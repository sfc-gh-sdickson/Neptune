{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neptune ML Models - Model Registry\n",
        "\n",
        "This notebook trains ML models for the Neptune Intelligence Agent:\n",
        "- **Consumption Forecasting** - Predict future monthly water consumption\n",
        "- **Utility Churn Prediction** - Classify utilities at risk of churning\n",
        "- **Meter Deployment Success** - Predict which meter deployments will be successful\n",
        "\n",
        "All models are registered to Snowflake Model Registry.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import snowflake.snowpark.functions as F\n",
        "import snowflake.snowpark.types as T\n",
        "\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression, LogisticRegression\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import mean_absolute_error, accuracy_score\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "print(\"✅ Packages imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to Snowflake\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session = get_active_session()\n",
        "session.use_database('NEPTUNE_INTELLIGENCE')\n",
        "session.use_schema('ANALYTICS')\n",
        "session.use_warehouse('NEPTUNE_WH')\n",
        "\n",
        "print(f\"✅ Connected - Role: {session.get_current_role()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 1: Consumption Forecasting\n",
        "\n",
        "Predict future monthly water consumption using historical data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Consumption Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "consumption_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    DATE_TRUNC('month', reading_timestamp)::DATE AS reading_month,\n",
        "    MONTH(reading_timestamp) AS month_num,\n",
        "    YEAR(reading_timestamp) AS year_num,\n",
        "    SUM(consumption_gallons)::FLOAT AS total_consumption,\n",
        "    COUNT(DISTINCT meter_serial_number)::FLOAT AS active_meters,\n",
        "    COUNT(DISTINCT utility_id)::FLOAT AS active_utilities\n",
        "FROM RAW.METER_READINGS\n",
        "WHERE reading_timestamp >= DATEADD('month', -36, CURRENT_DATE())\n",
        "GROUP BY 1, 2, 3\n",
        "ORDER BY 1\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Consumption data: {consumption_df.count()} months\")\n",
        "consumption_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Consumption Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_consumption, test_consumption = consumption_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "train_consumption = train_consumption.drop(\"READING_MONTH\")\n",
        "test_consumption = test_consumption.drop(\"READING_MONTH\")\n",
        "\n",
        "consumption_pipeline = Pipeline([\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"MONTH_NUM\", \"ACTIVE_METERS\", \"ACTIVE_UTILITIES\"],\n",
        "        output_cols=[\"MONTH_NUM_SCALED\", \"ACTIVE_METERS_SCALED\", \"ACTIVE_UTILITIES_SCALED\"]\n",
        "    )),\n",
        "    (\"LinearRegression\", LinearRegression(\n",
        "        label_cols=[\"TOTAL_CONSUMPTION\"],\n",
        "        output_cols=[\"PREDICTED_CONSUMPTION\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "consumption_pipeline.fit(train_consumption)\n",
        "print(\"✅ Consumption forecasting model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Consumption Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = consumption_pipeline.predict(test_consumption)\n",
        "mae = mean_absolute_error(df=predictions, y_true_col_names=\"TOTAL_CONSUMPTION\", y_pred_col_names=\"PREDICTED_CONSUMPTION\")\n",
        "metrics = {\"mae\": round(mae, 2)}\n",
        "print(f\"Consumption model metrics: {metrics}\")\n",
        "\n",
        "reg = Registry(session)\n",
        "reg.log_model(\n",
        "    model=consumption_pipeline,\n",
        "    model_name=\"CONSUMPTION_FORECASTER\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts monthly water consumption using Linear Regression.\",\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Consumption model registered to Model Registry as CONSUMPTION_FORECASTER\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 2: Utility Churn Prediction\n",
        "\n",
        "Classify utilities as likely to churn or not based on their operational patterns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Churn Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "churn_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    u.utility_id,\n",
        "    u.utility_type,\n",
        "    u.service_population::FLOAT AS service_population,\n",
        "    COUNT(DISTINCT wo.work_order_id)::FLOAT AS total_work_orders,\n",
        "    AVG(wo.customer_satisfaction_score)::FLOAT AS avg_satisfaction,\n",
        "    COUNT(DISTINCT CASE WHEN mr.anomaly_detected THEN mr.reading_id END)::FLOAT AS anomaly_count,\n",
        "    (u.utility_status = 'INACTIVE')::BOOLEAN AS is_churned -- Simplified target\n",
        "FROM RAW.UTILITIES u\n",
        "LEFT JOIN RAW.WORK_ORDERS wo ON u.utility_id = wo.utility_id\n",
        "LEFT JOIN RAW.METER_READINGS mr ON u.utility_id = mr.utility_id\n",
        "WHERE u.utility_status IN ('ACTIVE', 'INACTIVE')\n",
        "GROUP BY 1, 2, 3, 7\n",
        "LIMIT 5000\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Churn data: {churn_df.count()} utilities\")\n",
        "churn_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Churn Classification Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_churn, test_churn = churn_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "train_churn = train_churn.drop(\"UTILITY_ID\")\n",
        "test_churn = test_churn.drop(\"UTILITY_ID\")\n",
        "\n",
        "churn_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"UTILITY_TYPE\"],\n",
        "        output_cols=[\"UTILITY_TYPE_ENCODED\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"IS_CHURNED\"],\n",
        "        output_cols=[\"CHURN_PREDICTION\"],\n",
        "        n_estimators=100\n",
        "    ))\n",
        "])\n",
        "\n",
        "churn_pipeline.fit(train_churn)\n",
        "print(\"✅ Churn classification model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Churn Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "churn_predictions = churn_pipeline.predict(test_churn)\n",
        "accuracy = accuracy_score(df=churn_predictions, y_true_col_names=\"IS_CHURNED\", y_pred_col_names=\"CHURN_PREDICTION\")\n",
        "churn_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Churn model metrics: {churn_metrics}\")\n",
        "\n",
        "reg.log_model(\n",
        "    model=churn_pipeline,\n",
        "    model_name=\"UTILITY_CHURN_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts utility churn risk using a Random Forest classifier.\",\n",
        "    metrics=churn_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Churn model registered to Model Registry as UTILITY_CHURN_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 3: Meter Deployment Success Prediction\n",
        "\n",
        "Predict which meter deployments will be successful (i.e., remain active and report data).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Deployment Success Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "success_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    mi.meter_serial_number,\n",
        "    mc.meter_family,\n",
        "    mc.technology,\n",
        "    u.utility_type,\n",
        "    DATEDIFF('year', u.onboarding_date, CURRENT_DATE())::FLOAT AS utility_age_years,\n",
        "    (mi.meter_status = 'DEPLOYED' AND mi.last_sync_date >= DATEADD('month', -3, CURRENT_DATE()))::BOOLEAN AS is_successful\n",
        "FROM RAW.METER_INVENTORY mi\n",
        "JOIN RAW.METER_CATALOG mc ON mi.meter_model_id = mc.meter_model_id\n",
        "JOIN RAW.UTILITIES u ON mi.utility_id = u.utility_id\n",
        "LIMIT 10000 -- Limit for faster training\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Deployment success data: {success_df.count()} meters\")\n",
        "success_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Deployment Success Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_success, test_success = success_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "train_success = train_success.drop(\"METER_SERIAL_NUMBER\")\n",
        "test_success = test_success.drop(\"METER_SERIAL_NUMBER\")\n",
        "\n",
        "success_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"METER_FAMILY\", \"TECHNOLOGY\", \"UTILITY_TYPE\"],\n",
        "        output_cols=[\"METER_FAMILY_ENC\", \"TECHNOLOGY_ENC\", \"UTILITY_TYPE_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", LogisticRegression(\n",
        "        label_cols=[\"IS_SUCCESSFUL\"],\n",
        "        output_cols=[\"SUCCESS_PREDICTION\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "success_pipeline.fit(train_success)\n",
        "print(\"✅ Deployment success model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Deployment Success Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "success_predictions = success_pipeline.predict(test_success)\n",
        "accuracy = accuracy_score(df=success_predictions, y_true_col_names=\"IS_SUCCESSFUL\", y_pred_col_names=\"SUCCESS_PREDICTION\")\n",
        "success_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Deployment success model metrics: {success_metrics}\")\n",
        "\n",
        "reg.log_model(\n",
        "    model=success_pipeline,\n",
        "    model_name=\"DEPLOYMENT_SUCCESS_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts meter deployment success using Logistic Regression.\",\n",
        "    metrics=success_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Deployment success model registered as DEPLOYMENT_SUCCESS_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Verify Models in Registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Models in registry:\")\n",
        "reg.show_models()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
